{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from time import time\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "import numpy as np\n",
    "# Import supplementary visualization code visuals.py\n",
    "#import visuals as vs\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting files and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_data= \"/home/ubuntu/udacity/CodeGladiator/invesco/data\"\n",
    "\n",
    "transaction_file = \"Code-Gladiators-Transaction.csv\"\n",
    "#investment_exp_file = \"Code-Gladiators-InvestmentExperience.csv\"\n",
    "investment_exp_file = \"imputed_investment_exp.csv\"\n",
    "investment_segment = \"investment_vehicle_segment.csv\"\n",
    "aum_file = \"Code-Gladiators-AUM.csv\"\n",
    "activity_file = \"Code-Gladiators-Activity.csv\"\n",
    "\n",
    "test_file = \"test_data.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reading csv files into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transaction_df = pd.read_csv(os.path.join(path_to_data, transaction_file))\n",
    "investment_exp_df = pd.read_csv(os.path.join(path_to_data, investment_exp_file))\n",
    "investment_segment_df = pd.read_csv(os.path.join(path_to_data, investment_segment))\n",
    "aum_df = pd.read_csv(os.path.join(path_to_data, aum_file))\n",
    "activity_df = pd.read_csv(os.path.join(path_to_data, activity_file))\n",
    "test_df = pd.read_csv(os.path.join(path_to_data,test_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Import two metrics from sklearn - fbeta_score and accuracy_score\n",
    "from sklearn.metrics import fbeta_score, accuracy_score\n",
    "# time.time() return time in seconds since the Epoch\n",
    "from time import time\n",
    "\n",
    "beta = 0.5\n",
    "\n",
    "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       - sample_size: the size of samples (number) to be drawn from training set\n",
    "       - X_train: features training set\n",
    "       - y_train: income training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: income testing set\n",
    "    '''\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # TODO: Fit the learner to the training data using slicing with 'sample_size'\n",
    "    X_train = X_train[:sample_size]\n",
    "    y_train = y_train[:sample_size]\n",
    "    \n",
    "    start = time() # Get start time\n",
    "    learner.fit(X_train, y_train)\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # TODO: Calculate the training time\n",
    "    results['train_time'] = end - start\n",
    "        \n",
    "    # TODO: Get the predictions on the test set,\n",
    "    #       then get predictions on the first 300 training samples\n",
    "    start = time() # Get start time\n",
    "    predictions_test = learner.predict(X_test)\n",
    "    predictions_train = learner.predict(X_train)\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # TODO: Calculate the total prediction time\n",
    "    results['pred_time'] = end-start\n",
    "            \n",
    "    # TODO: Compute accuracy on the first 300 training samples\n",
    "    results['acc_train'] = accuracy_score(y_train, predictions_train)\n",
    "        \n",
    "    # TODO: Compute accuracy on test set\n",
    "    results['acc_test'] = accuracy_score(y_test, predictions_test)\n",
    "    \n",
    "    # TODO: Compute F-score on the the first 300 training samples\n",
    "    results['f_train'] = fbeta_score(y_train, predictions_train, beta=beta)\n",
    "        \n",
    "   # TODO: Compute F-score on the test set\n",
    "    results['f_test'] = fbeta_score(y_test, predictions_test, beta=beta)\n",
    "       \n",
    "    # Success\n",
    "    print (\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
    "        \n",
    "    # Return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_list= [\n",
    "    'Transaction_Type',\n",
    "#    'Shares_investor',\n",
    "#    'AUM_investor',\n",
    "     'Counts_investor',\n",
    "#     'Counts_advisor',\n",
    "#\t'Shares_advisor',\n",
    "#\t'AUM_advisor',\n",
    "#\t'Morningstar Category',\n",
    "#\t'Investment',\n",
    "\t'Rating',\n",
    "\t'1 Yr % Rank',\n",
    "\t'3 Yr % Rank',\n",
    "#\t'5 Yr % Rank',\n",
    "#\t'10 Yr % Rank',\n",
    "\t'1 Yr Return',\n",
    "\t'3 Yr Return',\n",
    "#\t'5 Yr Return',\n",
    "#\t'10 Yr Return',\n",
    "\t'1 Yr Excess Return vs Primary Ix',\n",
    "\t'3 Yr Excess Return vs Primary Ix',\n",
    "#\t'5 Yr Excess Return vs Primary Ix',\n",
    "#\t'10 Yr Excess Return vs Primary Ix',\n",
    "\t'1 Yr Excess Return vs Category Ix',\n",
    "\t'3 Yr Excess Return vs Category Ix',\n",
    "#\t'5 Yr Excess Return vs Category Ix',\n",
    "#\t'10 Yr Excess Return vs Category Ix',\n",
    "\t'Net Flows',\n",
    "\t'Morningstar_Category_Rating',\n",
    "\t'investment_vehicle_segment',\n",
    "\t'AUM_investor_log',\n",
    "\t'Shares_investor_log',\n",
    "\t'AUM_advisor_log',\n",
    "\t'Shares_advisor_log',\n",
    "\t]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### processing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping data by unique advisor id and month. Final output will store sums of the assets under managements and shares for each advisor in particular month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/ipykernel/__main__.py:69: RuntimeWarning: divide by zero encountered in log\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/ipykernel/__main__.py:71: RuntimeWarning: divide by zero encountered in log\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/ipykernel/__main__.py:72: RuntimeWarning: divide by zero encountered in log\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/ipykernel/__main__.py:76: RuntimeWarning: divide by zero encountered in log\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/ipykernel/__main__.py:79: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 99782 samples.\n",
      "Testing set has 24946 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/scipy/optimize/linesearch.py:414: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression trained on 99782 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression': {0: {'acc_test': 0.66639942275314679,\n",
       "   'acc_train': 0.66559098835461306,\n",
       "   'f_test': 0.71397317814872341,\n",
       "   'f_train': 0.71454756355120763,\n",
       "   'pred_time': 0.006248950958251953,\n",
       "   'train_time': 15.810226678848267}}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-156e6497b988>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_loaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0mpred_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_loaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \"\"\"\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    310\u001b[0m                                  \"yet\" % {'name': type(self).__name__})\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "transaction_df = pd.read_csv(os.path.join(path_to_data, transaction_file))\n",
    "investment_exp_df = pd.read_csv(os.path.join(path_to_data, investment_exp_file))\n",
    "investment_segment_df = pd.read_csv(os.path.join(path_to_data, investment_segment))\n",
    "aum_df = pd.read_csv(os.path.join(path_to_data, aum_file))\n",
    "activity_df = pd.read_csv(os.path.join(path_to_data, activity_file))\n",
    "test_df = pd.read_csv(os.path.join(path_to_data,test_file))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "grouped_advisor_aum_df = aum_df.groupby(['Unique_Advisor_Id','Month']).agg({'AUM': 'sum','Shares':'sum','Unique_Investment_Id':'count'}).reset_index().rename(columns={'Unique_Investment_Id':'Counts'})\n",
    "grouped_investment_aum_df = aum_df.groupby(['Unique_Investment_Id','Month']).agg({'AUM': 'sum','Shares':'sum','Unique_Advisor_Id':'count'}).reset_index().rename(columns={'Unique_Advisor_Id':'Counts'})\n",
    "\n",
    "grouped_investment_aum_df['Year'],grouped_investment_aum_df['Month']=grouped_investment_aum_df['Month'].str.split(' /', 1).str\n",
    "grouped_advisor_aum_df['Year'],grouped_advisor_aum_df['Month']=grouped_advisor_aum_df['Month'].str.split(' /', 1).str\n",
    "\n",
    "transaction_df['Year'],transaction_df['Month']=transaction_df['Month'].str.split(' /', 1).str\n",
    "investment_exp_df['Year'],investment_exp_df['Month']=investment_exp_df['Month'].str.split(' /', 1).str\n",
    "aum_df['Year'],aum_df['Month']=aum_df['Month'].str.split(' /', 1).str\n",
    "activity_df['Year'],activity_df['Month']=activity_df['Month'].str.split(' /', 1).str\n",
    "\n",
    "grouped_investment_aum_df['Mapping_Month']= grouped_investment_aum_df['Month'].astype(int).apply(lambda x : x+1)\n",
    "grouped_advisor_aum_df['Mapping_Month']= grouped_advisor_aum_df['Month'].astype(int).apply(lambda x : x+1)\n",
    "investment_exp_df['Mapping_Month']= investment_exp_df['Month'].astype(int).apply(lambda x : x+1)\n",
    "aum_df['Mapping_Month']= aum_df['Month'].astype(int).apply(lambda x : x+1)\n",
    "activity_df['Mapping_Month']= activity_df['Month'].astype(int).apply(lambda x : x+1)\n",
    "\n",
    "transaction_df['Month'] =  transaction_df['Month'].astype(int).apply(lambda x : x+0)\n",
    "\n",
    "final_transaction = pd.merge(transaction_df, grouped_investment_aum_df, left_on=[\"Month\",\"Unique_Investment_Id\"],right_on=[\"Mapping_Month\",\"Unique_Investment_Id\"], how=\"left\") \n",
    "final_transaction = final_transaction.rename(columns={'Month_x': 'Month', 'AUM': 'AUM_investor','Year_x' : 'Year', 'Counts' : 'Counts_investor', 'Shares': 'Shares_investor','Month_y':'Month_actual'})\n",
    "final_transaction = final_transaction.drop('Year_y', 1)\n",
    "\n",
    "test_transaction = pd.merge(test_df, grouped_investment_aum_df[grouped_investment_aum_df[\"Mapping_Month\"]== 13], on=\"Unique_Investment_Id\", how=\"left\")\n",
    "test_transaction = test_transaction.rename(columns={ 'AUM': 'AUM_investor','Counts' : 'Counts_investor', 'Shares': 'Shares_investor'})\n",
    "\n",
    "final_transaction = pd.merge(final_transaction, grouped_advisor_aum_df, left_on=[\"Month\",\"Unique_Advisor_Id\"],right_on=[\"Mapping_Month\",\"Unique_Advisor_Id\"], how=\"left\") \n",
    "final_transaction = final_transaction.rename(columns={'Month_x': 'Month', 'AUM': 'AUM_advisor','Year_x' : 'Year', 'Counts' : 'Counts_advisor', 'Shares': 'Shares_advisor','Mapping_Month_x': 'Mapping_Month'})\n",
    "final_transaction = final_transaction.drop(['Year_y','Mapping_Month_y','Month_y'], 1)\n",
    "\n",
    "test_transaction = pd.merge(test_transaction, grouped_advisor_aum_df[grouped_advisor_aum_df[\"Mapping_Month\"]== 13], on=\"Unique_Advisor_Id\", how=\"left\")\n",
    "test_transaction = test_transaction.rename(columns={ 'AUM': 'AUM_advisor','Counts' : 'Counts_advisor', 'Shares': 'Shares_advisor','Month_x':'Month','Mapping_Month_x':'Mapping_Month'})\n",
    "test_transaction = test_transaction.drop(['Year_x','Year_y','Mapping_Month_y','Month_y','Mapping_Month'], 1)\n",
    "\n",
    "investment_exp_df['investment_vehicle_segment']= investment_segment_df['investment_vehicle_segment']\n",
    "investment_exp_df= investment_exp_df[investment_exp_df['Year']=='2016']\n",
    "\n",
    "final_transaction_with_exp = pd.merge(final_transaction, investment_exp_df, left_on=[\"Month\",\"Unique_Investment_Id\"],right_on=[\"Mapping_Month\",\"Unique_Investment_Id\"], how=\"left\") \n",
    "final_transaction_with_exp = final_transaction_with_exp.rename(columns={'Month_x': 'Month', 'AUM': 'AUM_advisor','Year_x' : 'Year', 'Mapping_Month_x':'Mapping_Month'})\n",
    "final_transaction_with_exp = final_transaction_with_exp.drop(['Year_y','Mapping_Month_y','Month_y'], 1)\n",
    "\n",
    "test_transaction_with_exp = pd.merge(test_transaction, investment_exp_df[investment_exp_df[\"Mapping_Month\"]== 13 ], on=\"Unique_Investment_Id\", how=\"left\")\n",
    "\n",
    "'''\n",
    "final_transaction_with_exp['AUM_investor_log'] = np.log(final_transaction_with_exp['AUM_investor'])\n",
    "final_transaction_with_exp['Shares_investor_log'] = np.log(final_transaction_with_exp['Shares_investor'])\n",
    "\n",
    "final_transaction_with_exp['AUM_advisor_log'] = np.log(final_transaction_with_exp['AUM_advisor'])\n",
    "final_transaction_with_exp['Shares_advisor_log'] = np.log(final_transaction_with_exp['Shares_advisor'])\n",
    "\n",
    "\n",
    "test_transaction_with_exp['AUM_investor_log'] = np.log(test_transaction_with_exp['AUM_investor'])\n",
    "test_transaction_with_exp['Shares_investor_log'] = np.log(test_transaction_with_exp['Shares_investor'])\n",
    "\n",
    "test_transaction_with_exp['AUM_advisor_log'] = np.log(test_transaction_with_exp['AUM_advisor'])\n",
    "test_transaction_with_exp['Shares_advisor_log'] = np.log(test_transaction_with_exp['Shares_advisor'])\n",
    "'''\n",
    "final_transaction_with_exp['AUM_investor_log'] = np.log(final_transaction_with_exp['AUM_investor']/final_transaction_with_exp['Counts_investor']).where(final_transaction_with_exp['AUM_investor']!=0)\n",
    "final_transaction_with_exp['Shares_investor_log'] = np.log(final_transaction_with_exp['Shares_investor']/final_transaction_with_exp['Counts_investor']).where(final_transaction_with_exp['Shares_investor']!=0)\n",
    "\n",
    "final_transaction_with_exp['AUM_advisor_log'] = np.log(final_transaction_with_exp['AUM_advisor']/final_transaction_with_exp['Counts_advisor']).where(final_transaction_with_exp['AUM_advisor']!=0)\n",
    "final_transaction_with_exp['Shares_advisor_log'] = np.log(final_transaction_with_exp['Shares_advisor']/final_transaction_with_exp['Counts_advisor']).where(final_transaction_with_exp['Shares_advisor']!=0)\n",
    "\n",
    "\n",
    "test_transaction_with_exp['AUM_investor_log'] = np.log(test_transaction_with_exp['AUM_investor']/test_transaction_with_exp['Counts_investor']).where(final_transaction_with_exp['AUM_investor']!=0)\n",
    "test_transaction_with_exp['Shares_investor_log'] = np.log(test_transaction_with_exp['Shares_investor']/test_transaction_with_exp['Counts_investor']).where(final_transaction_with_exp['Shares_investor']!=0)\n",
    "\n",
    "test_transaction_with_exp['AUM_advisor_log'] = np.log(test_transaction_with_exp['AUM_advisor']/test_transaction_with_exp['Counts_advisor']).where(final_transaction_with_exp['AUM_advisor']!=0)\n",
    "test_transaction_with_exp['Shares_advisor_log'] = np.log(test_transaction_with_exp['Shares_advisor']/test_transaction_with_exp['Counts_advisor']).where(final_transaction_with_exp['Shares_advisor']!=0)\n",
    "final_transaction_with_exp= final_transaction_with_exp.dropna()\n",
    "\n",
    "\n",
    "required_train_df = final_transaction_with_exp.filter(column_list)\n",
    "\n",
    "required_train_df['Transaction_Type']= required_train_df.apply(lambda x: 0 if x['Transaction_Type']== 'P' else 1, axis=1)\n",
    "\n",
    "required_test_df = test_transaction_with_exp.filter(column_list)\n",
    "\n",
    "\n",
    "#required_test_df['Rating'] = required_test_df['Rating'].astype(float)\n",
    "\n",
    "required_test_df=required_test_df.fillna(required_test_df.median())\n",
    "\n",
    "# Split the data into features and target label\n",
    "transaction_type = required_train_df['Transaction_Type']\n",
    "features_raw = required_train_df.drop('Transaction_Type', axis = 1)\n",
    "test_raw = required_test_df\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "var_mod = column_list\n",
    "#var_mod.remove('Transaction_Type')\n",
    "le = LabelEncoder()\n",
    "for i in var_mod:\n",
    "    if i == 'Transaction_Type' \\\n",
    "    or i == 'Net Flows' \\\n",
    "    or i == 'AUM_investor_log' \\\n",
    "    or i == 'Shares_investor_log' \\\n",
    "    or i == 'AUM_advisor_log' \\\n",
    "    or i == 'Shares_advisor_log':\n",
    "        continue\n",
    "    features_raw[i] = le.fit_transform(features_raw[i])\n",
    "    test_raw[i] = le.fit_transform(test_raw[i])\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Split the 'features' and 'transaction_type' data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_raw, transaction_type, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Show the results of the split\n",
    "print (\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print (\"Testing set has {} samples.\".format(X_test.shape[0]))\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "\n",
    "# TODO: Import the three supervised learning models from sklearn\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# TODO: Initialize the three models\n",
    "clf_A = LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
    "          verbose=0, warm_start=False)\n",
    "clf_B = LinearSVC(random_state=101)\n",
    "clf_C = GaussianNB()\n",
    "clf_Ada = AdaBoostClassifier()\n",
    "clf_Grad = GradientBoostingClassifier()\n",
    "clf_KNN = KNeighborsClassifier()\n",
    "clf_Dec = DecisionTreeClassifier()\n",
    "clf_SGD = SGDClassifier()\n",
    "\n",
    "\n",
    "# TODO: Calculate the number of samples for 1%, 10%, and 100% of the training data\n",
    "n_train = len(y_train)\n",
    "samples_1 = int(n_train * 0.01)\n",
    "samples_10 = int(n_train * 0.1)\n",
    "samples_100 = n_train\n",
    "\n",
    "# Collect results on the learners\n",
    "results = {}\n",
    "#for clf in [clf_A, clf_B, clf_C, clf_Ada, clf_Grad,clf_KNN ,clf_Dec, clf_SGD]:\n",
    "for clf in [clf_A]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    results[clf_name] = {}\n",
    "    for i, samples in enumerate([samples_100]):\n",
    "        results[clf_name][i] = \\\n",
    "        train_predict(clf, samples, X_train, y_train, X_test, y_test)\n",
    "        \n",
    "display(results)\n",
    "\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "best_clf= clf_A\n",
    "filename = 'logistic_regression_best_invesco.joblib.pkl'\n",
    "\n",
    "_ = joblib.dump(best_clf, filename, compress=9)\n",
    "\n",
    "clf_loaded = joblib.load(filename)\n",
    "\n",
    "\n",
    "pred = clf_loaded.predict(test_raw)\n",
    "pred_prob = clf_loaded.predict_proba(test_raw)\n",
    "\n",
    "pred_prob = pd.DataFrame(pred_prob[:,1],columns=[\"Propensity_Score\"])\n",
    "display(pred_prob[:5])\n",
    "\n",
    "pred_df= pd.DataFrame(pred,columns=[\"Redeem_Status\"])\n",
    "\n",
    "pred_df=pred_df.replace([0,1],['NO','YES'])\n",
    "pred_df.head()\n",
    "\n",
    "pred_df['Redeem_Status'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_raw=test_raw.apply(lambda x: 0 if x['Shares_investor_log']== \"-inf\" else x['Shares_investor_log'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Counts_investor</th>\n",
       "      <th>Rating</th>\n",
       "      <th>1 Yr % Rank</th>\n",
       "      <th>3 Yr % Rank</th>\n",
       "      <th>1 Yr Return</th>\n",
       "      <th>3 Yr Return</th>\n",
       "      <th>1 Yr Excess Return vs Primary Ix</th>\n",
       "      <th>3 Yr Excess Return vs Primary Ix</th>\n",
       "      <th>1 Yr Excess Return vs Category Ix</th>\n",
       "      <th>3 Yr Excess Return vs Category Ix</th>\n",
       "      <th>Net Flows</th>\n",
       "      <th>Morningstar_Category_Rating</th>\n",
       "      <th>investment_vehicle_segment</th>\n",
       "      <th>AUM_investor_log</th>\n",
       "      <th>Shares_investor_log</th>\n",
       "      <th>AUM_advisor_log</th>\n",
       "      <th>Shares_advisor_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8714.000000</td>\n",
       "      <td>8714.000000</td>\n",
       "      <td>8714.000000</td>\n",
       "      <td>8714.000000</td>\n",
       "      <td>8714.000000</td>\n",
       "      <td>8714.000000</td>\n",
       "      <td>8714.000000</td>\n",
       "      <td>8714.000000</td>\n",
       "      <td>8714.000000</td>\n",
       "      <td>8714.000000</td>\n",
       "      <td>8.714000e+03</td>\n",
       "      <td>8714.000000</td>\n",
       "      <td>8714.000000</td>\n",
       "      <td>8714.000000</td>\n",
       "      <td>8714.000000</td>\n",
       "      <td>8714.000000</td>\n",
       "      <td>8714.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>122.700252</td>\n",
       "      <td>2.360913</td>\n",
       "      <td>34.461556</td>\n",
       "      <td>38.991737</td>\n",
       "      <td>162.904177</td>\n",
       "      <td>176.143218</td>\n",
       "      <td>119.862635</td>\n",
       "      <td>136.800321</td>\n",
       "      <td>133.363438</td>\n",
       "      <td>134.629676</td>\n",
       "      <td>-1.261598e+09</td>\n",
       "      <td>1.092724</td>\n",
       "      <td>3.320060</td>\n",
       "      <td>11.380379</td>\n",
       "      <td>-inf</td>\n",
       "      <td>11.130152</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>46.416504</td>\n",
       "      <td>0.892727</td>\n",
       "      <td>23.386982</td>\n",
       "      <td>25.350470</td>\n",
       "      <td>80.016941</td>\n",
       "      <td>76.706912</td>\n",
       "      <td>70.874669</td>\n",
       "      <td>61.746068</td>\n",
       "      <td>77.218873</td>\n",
       "      <td>73.680023</td>\n",
       "      <td>2.221631e+09</td>\n",
       "      <td>0.520340</td>\n",
       "      <td>2.175591</td>\n",
       "      <td>0.867439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.099760</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.125907e+10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.641642</td>\n",
       "      <td>-inf</td>\n",
       "      <td>2.042129</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>105.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>124.250000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>-2.289336e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.917573</td>\n",
       "      <td>7.941031</td>\n",
       "      <td>10.569123</td>\n",
       "      <td>7.800445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>142.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>-1.376592e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>11.517027</td>\n",
       "      <td>8.366975</td>\n",
       "      <td>11.140159</td>\n",
       "      <td>8.350701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>157.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>-2.801090e+08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>11.781417</td>\n",
       "      <td>9.026056</td>\n",
       "      <td>11.672049</td>\n",
       "      <td>8.918621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>165.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>5.783243e+09</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>15.120249</td>\n",
       "      <td>11.742698</td>\n",
       "      <td>16.778460</td>\n",
       "      <td>12.923589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Counts_investor       Rating  1 Yr % Rank  3 Yr % Rank  1 Yr Return  \\\n",
       "count      8714.000000  8714.000000  8714.000000  8714.000000  8714.000000   \n",
       "mean        122.700252     2.360913    34.461556    38.991737   162.904177   \n",
       "std          46.416504     0.892727    23.386982    25.350470    80.016941   \n",
       "min           0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%         105.000000     2.000000    14.000000    15.000000    84.000000   \n",
       "50%         142.000000     2.000000    34.000000    43.000000   195.000000   \n",
       "75%         157.000000     3.000000    50.000000    60.000000   232.000000   \n",
       "max         165.000000     4.000000    87.000000    90.000000   270.000000   \n",
       "\n",
       "       3 Yr Return  1 Yr Excess Return vs Primary Ix  \\\n",
       "count  8714.000000                       8714.000000   \n",
       "mean    176.143218                        119.862635   \n",
       "std      76.706912                         70.874669   \n",
       "min       0.000000                          0.000000   \n",
       "25%     124.250000                         53.000000   \n",
       "50%     199.000000                        127.000000   \n",
       "75%     235.000000                        187.000000   \n",
       "max     270.000000                        251.000000   \n",
       "\n",
       "       3 Yr Excess Return vs Primary Ix  1 Yr Excess Return vs Category Ix  \\\n",
       "count                       8714.000000                        8714.000000   \n",
       "mean                         136.800321                         133.363438   \n",
       "std                           61.746068                          77.218873   \n",
       "min                            0.000000                           0.000000   \n",
       "25%                           91.000000                          66.000000   \n",
       "50%                          132.000000                         135.000000   \n",
       "75%                          196.000000                         197.000000   \n",
       "max                          250.000000                         270.000000   \n",
       "\n",
       "       3 Yr Excess Return vs Category Ix     Net Flows  \\\n",
       "count                        8714.000000  8.714000e+03   \n",
       "mean                          134.629676 -1.261598e+09   \n",
       "std                            73.680023  2.221631e+09   \n",
       "min                             0.000000 -1.125907e+10   \n",
       "25%                            71.000000 -2.289336e+09   \n",
       "50%                           129.000000 -1.376592e+09   \n",
       "75%                           195.000000 -2.801090e+08   \n",
       "max                           270.000000  5.783243e+09   \n",
       "\n",
       "       Morningstar_Category_Rating  investment_vehicle_segment  \\\n",
       "count                  8714.000000                 8714.000000   \n",
       "mean                      1.092724                    3.320060   \n",
       "std                       0.520340                    2.175591   \n",
       "min                       0.000000                    0.000000   \n",
       "25%                       1.000000                    2.000000   \n",
       "50%                       1.000000                    3.000000   \n",
       "75%                       1.000000                    6.000000   \n",
       "max                       3.000000                    6.000000   \n",
       "\n",
       "       AUM_investor_log  Shares_investor_log  AUM_advisor_log  \\\n",
       "count       8714.000000          8714.000000      8714.000000   \n",
       "mean          11.380379                 -inf        11.130152   \n",
       "std            0.867439                  NaN         1.099760   \n",
       "min            6.641642                 -inf         2.042129   \n",
       "25%           10.917573             7.941031        10.569123   \n",
       "50%           11.517027             8.366975        11.140159   \n",
       "75%           11.781417             9.026056        11.672049   \n",
       "max           15.120249            11.742698        16.778460   \n",
       "\n",
       "       Shares_advisor_log  \n",
       "count         8714.000000  \n",
       "mean                 -inf  \n",
       "std                   NaN  \n",
       "min                  -inf  \n",
       "25%              7.800445  \n",
       "50%              8.350701  \n",
       "75%              8.918621  \n",
       "max             12.923589  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique_Advisor_Id</th>\n",
       "      <th>Unique_Investment_Id</th>\n",
       "      <th>Month</th>\n",
       "      <th>Code_1</th>\n",
       "      <th>Code_2</th>\n",
       "      <th>Code_3</th>\n",
       "      <th>Code_4</th>\n",
       "      <th>Code_5</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Shares_investor</th>\n",
       "      <th>...</th>\n",
       "      <th>3 Yr Excess Return vs Category Ix</th>\n",
       "      <th>5 Yr Excess Return vs Category Ix</th>\n",
       "      <th>10 Yr Excess Return vs Category Ix</th>\n",
       "      <th>Net Flows</th>\n",
       "      <th>Morningstar_Category_Rating</th>\n",
       "      <th>investment_vehicle_segment</th>\n",
       "      <th>AUM_investor_log</th>\n",
       "      <th>Shares_investor_log</th>\n",
       "      <th>AUM_advisor_log</th>\n",
       "      <th>Shares_advisor_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.252020e+05</td>\n",
       "      <td>125202.000000</td>\n",
       "      <td>125202.000000</td>\n",
       "      <td>125202.000000</td>\n",
       "      <td>125202.000000</td>\n",
       "      <td>125202.000000</td>\n",
       "      <td>125202.000000</td>\n",
       "      <td>125202.000000</td>\n",
       "      <td>1.252020e+05</td>\n",
       "      <td>1.252020e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>125202.000000</td>\n",
       "      <td>125202.000000</td>\n",
       "      <td>125202.000000</td>\n",
       "      <td>1.252020e+05</td>\n",
       "      <td>125202.000000</td>\n",
       "      <td>125202.000000</td>\n",
       "      <td>125202.000000</td>\n",
       "      <td>1.252020e+05</td>\n",
       "      <td>1.252020e+05</td>\n",
       "      <td>1.252020e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.922556e+05</td>\n",
       "      <td>7063.039480</td>\n",
       "      <td>7.054680</td>\n",
       "      <td>2.483443</td>\n",
       "      <td>23.314588</td>\n",
       "      <td>1.007644</td>\n",
       "      <td>16.489856</td>\n",
       "      <td>2.226147</td>\n",
       "      <td>-1.923565e+03</td>\n",
       "      <td>3.052929e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.631375</td>\n",
       "      <td>-2.322545</td>\n",
       "      <td>-0.290030</td>\n",
       "      <td>-2.701917e+08</td>\n",
       "      <td>2.955528</td>\n",
       "      <td>4.052307</td>\n",
       "      <td>10.046129</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.087141e+05</td>\n",
       "      <td>5985.539006</td>\n",
       "      <td>3.129099</td>\n",
       "      <td>3.275153</td>\n",
       "      <td>11.815030</td>\n",
       "      <td>0.151237</td>\n",
       "      <td>9.690987</td>\n",
       "      <td>1.416558</td>\n",
       "      <td>6.965335e+04</td>\n",
       "      <td>1.886451e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>3.002261</td>\n",
       "      <td>2.291126</td>\n",
       "      <td>0.810717</td>\n",
       "      <td>4.860562e+08</td>\n",
       "      <td>0.543448</td>\n",
       "      <td>1.678799</td>\n",
       "      <td>0.716779</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.224300e+04</td>\n",
       "      <td>3491.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-7.438030e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.634902</td>\n",
       "      <td>-5.447597</td>\n",
       "      <td>-0.727022</td>\n",
       "      <td>-4.307824e+09</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.458247</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.711540e+05</td>\n",
       "      <td>4021.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.261655e+03</td>\n",
       "      <td>2.750015e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.640019</td>\n",
       "      <td>-3.660431</td>\n",
       "      <td>-0.696837</td>\n",
       "      <td>-4.290873e+08</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.771769</td>\n",
       "      <td>7.585048e+00</td>\n",
       "      <td>1.061035e+01</td>\n",
       "      <td>7.820073e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.587780e+05</td>\n",
       "      <td>4021.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.192356e+02</td>\n",
       "      <td>3.514175e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.340148</td>\n",
       "      <td>-2.957552</td>\n",
       "      <td>-0.596162</td>\n",
       "      <td>-2.560913e+08</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.868567</td>\n",
       "      <td>7.655907e+00</td>\n",
       "      <td>1.124416e+01</td>\n",
       "      <td>8.487813e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.040468e+06</td>\n",
       "      <td>4363.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.119983e+02</td>\n",
       "      <td>3.693326e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.508981</td>\n",
       "      <td>-1.308510</td>\n",
       "      <td>-0.330070</td>\n",
       "      <td>1.616945e+06</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.960978</td>\n",
       "      <td>7.694847e+00</td>\n",
       "      <td>1.195220e+01</td>\n",
       "      <td>9.170489e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.118570e+06</td>\n",
       "      <td>20058.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.588394e+06</td>\n",
       "      <td>4.698612e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>8.233562</td>\n",
       "      <td>5.073673</td>\n",
       "      <td>3.492007</td>\n",
       "      <td>1.354974e+10</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.766932</td>\n",
       "      <td>1.120232e+01</td>\n",
       "      <td>1.630608e+01</td>\n",
       "      <td>1.319837e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unique_Advisor_Id  Unique_Investment_Id          Month         Code_1  \\\n",
       "count       1.252020e+05         125202.000000  125202.000000  125202.000000   \n",
       "mean        8.922556e+05           7063.039480       7.054680       2.483443   \n",
       "std         2.087141e+05           5985.539006       3.129099       3.275153   \n",
       "min         1.224300e+04           3491.000000       2.000000       1.000000   \n",
       "25%         7.711540e+05           4021.000000       4.000000       1.000000   \n",
       "50%         9.587780e+05           4021.000000       7.000000       2.000000   \n",
       "75%         1.040468e+06           4363.000000      10.000000       3.000000   \n",
       "max         1.118570e+06          20058.000000      12.000000      38.000000   \n",
       "\n",
       "              Code_2         Code_3         Code_4         Code_5  \\\n",
       "count  125202.000000  125202.000000  125202.000000  125202.000000   \n",
       "mean       23.314588       1.007644      16.489856       2.226147   \n",
       "std        11.815030       0.151237       9.690987       1.416558   \n",
       "min         2.000000       1.000000       1.000000       1.000000   \n",
       "25%        14.000000       1.000000       7.000000       1.000000   \n",
       "50%        22.000000       1.000000      20.000000       1.000000   \n",
       "75%        28.000000       1.000000      26.000000       4.000000   \n",
       "max        51.000000       4.000000      26.000000       4.000000   \n",
       "\n",
       "             Amount  Shares_investor         ...          \\\n",
       "count  1.252020e+05     1.252020e+05         ...           \n",
       "mean  -1.923565e+03     3.052929e+05         ...           \n",
       "std    6.965335e+04     1.886451e+05         ...           \n",
       "min   -7.438030e+06     0.000000e+00         ...           \n",
       "25%   -2.261655e+03     2.750015e+05         ...           \n",
       "50%   -1.192356e+02     3.514175e+05         ...           \n",
       "75%    3.119983e+02     3.693326e+05         ...           \n",
       "max    3.588394e+06     4.698612e+06         ...           \n",
       "\n",
       "       3 Yr Excess Return vs Category Ix  5 Yr Excess Return vs Category Ix  \\\n",
       "count                      125202.000000                      125202.000000   \n",
       "mean                           -2.631375                          -2.322545   \n",
       "std                             3.002261                           2.291126   \n",
       "min                            -8.634902                          -5.447597   \n",
       "25%                            -4.640019                          -3.660431   \n",
       "50%                            -3.340148                          -2.957552   \n",
       "75%                            -1.508981                          -1.308510   \n",
       "max                             8.233562                           5.073673   \n",
       "\n",
       "       10 Yr Excess Return vs Category Ix     Net Flows  \\\n",
       "count                       125202.000000  1.252020e+05   \n",
       "mean                            -0.290030 -2.701917e+08   \n",
       "std                              0.810717  4.860562e+08   \n",
       "min                             -0.727022 -4.307824e+09   \n",
       "25%                             -0.696837 -4.290873e+08   \n",
       "50%                             -0.596162 -2.560913e+08   \n",
       "75%                             -0.330070  1.616945e+06   \n",
       "max                              3.492007  1.354974e+10   \n",
       "\n",
       "       Morningstar_Category_Rating  investment_vehicle_segment  \\\n",
       "count                125202.000000               125202.000000   \n",
       "mean                      2.955528                    4.052307   \n",
       "std                       0.543448                    1.678799   \n",
       "min                       2.000000                    0.000000   \n",
       "25%                       3.000000                    3.000000   \n",
       "50%                       3.000000                    5.000000   \n",
       "75%                       3.000000                    5.000000   \n",
       "max                       4.000000                    6.000000   \n",
       "\n",
       "       AUM_investor_log  Shares_investor_log  AUM_advisor_log  \\\n",
       "count     125202.000000         1.252020e+05     1.252020e+05   \n",
       "mean          10.046129                 -inf             -inf   \n",
       "std            0.716779                  NaN              NaN   \n",
       "min            9.458247                 -inf             -inf   \n",
       "25%            9.771769         7.585048e+00     1.061035e+01   \n",
       "50%            9.868567         7.655907e+00     1.124416e+01   \n",
       "75%            9.960978         7.694847e+00     1.195220e+01   \n",
       "max           13.766932         1.120232e+01     1.630608e+01   \n",
       "\n",
       "       Shares_advisor_log  \n",
       "count        1.252020e+05  \n",
       "mean                 -inf  \n",
       "std                   NaN  \n",
       "min                  -inf  \n",
       "25%          7.820073e+00  \n",
       "50%          8.487813e+00  \n",
       "75%          9.170489e+00  \n",
       "max          1.319837e+01  \n",
       "\n",
       "[8 rows x 40 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_transaction_with_exp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique_Advisor_Id</th>\n",
       "      <th>Unique_Investment_Id</th>\n",
       "      <th>Propensity_Score</th>\n",
       "      <th>Redeem_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000103</td>\n",
       "      <td>14147</td>\n",
       "      <td>0.786417</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000103</td>\n",
       "      <td>3534</td>\n",
       "      <td>0.415081</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000103</td>\n",
       "      <td>3651</td>\n",
       "      <td>0.169032</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000103</td>\n",
       "      <td>7668</td>\n",
       "      <td>0.387780</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000103</td>\n",
       "      <td>9339</td>\n",
       "      <td>0.508985</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unique_Advisor_Id  Unique_Investment_Id  Propensity_Score Redeem_Status\n",
       "0            1000103                 14147          0.786417           YES\n",
       "1            1000103                  3534          0.415081            NO\n",
       "2            1000103                  3651          0.169032            NO\n",
       "3            1000103                  7668          0.387780            NO\n",
       "4            1000103                  9339          0.508985           YES"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.concat([test_df, pred_prob, pred_df], axis=1)\n",
    "\n",
    "result.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.to_csv('test_data_v3.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
