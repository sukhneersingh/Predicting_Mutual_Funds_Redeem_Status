{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from time import time\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Import supplementary visualization code visuals.py\n",
    "#import visuals as vs\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting files and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_data= \"/home/ubuntu/udacity/CodeGladiator/invesco/data\"\n",
    "\n",
    "transaction_file = \"Code-Gladiators-Transaction.csv\"\n",
    "\n",
    "####### adding new transaction fiel which have grouping of all the transactions\n",
    "#grouped_transaction_amounts = \"grouped_transaction_amounts.csv\"\n",
    "#investment_exp_file = \"Code-Gladiators-InvestmentExperience.csv\"\n",
    "investment_exp_file = \"imputed_investment_exp.csv\"\n",
    "investment_segment = \"investment_vehicle_segment.csv\"\n",
    "aum_file = \"Code-Gladiators-AUM.csv\"\n",
    "#activity_file = \"Code-Gladiators-Activity.csv\"\n",
    "activity_file = \"grouped_processed_activity.csv\"\n",
    "test_file = \"test_data.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reading csv files into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transaction_df = pd.read_csv(os.path.join(path_to_data, transaction_file))\n",
    "#grouped_transaction_amounts_df = pd.read_csv(os.path.join(path_to_data, grouped_transaction_amounts))\n",
    "investment_exp_df = pd.read_csv(os.path.join(path_to_data, investment_exp_file))\n",
    "investment_segment_df = pd.read_csv(os.path.join(path_to_data, investment_segment))\n",
    "aum_df = pd.read_csv(os.path.join(path_to_data, aum_file))\n",
    "activity_df = pd.read_csv(os.path.join(path_to_data, activity_file))\n",
    "test_df = pd.read_csv(os.path.join(path_to_data,test_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Import two metrics from sklearn - fbeta_score and accuracy_score\n",
    "from sklearn.metrics import fbeta_score, accuracy_score\n",
    "# time.time() return time in seconds since the Epoch\n",
    "from time import time\n",
    "\n",
    "beta = 0.5\n",
    "\n",
    "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       - sample_size: the size of samples (number) to be drawn from training set\n",
    "       - X_train: features training set\n",
    "       - y_train: income training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: income testing set\n",
    "    '''\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # TODO: Fit the learner to the training data using slicing with 'sample_size'\n",
    "    X_train = X_train[:sample_size]\n",
    "    y_train = y_train[:sample_size]\n",
    "    \n",
    "    start = time() # Get start time\n",
    "    learner.fit(X_train, y_train)\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # TODO: Calculate the training time\n",
    "    results['train_time'] = end - start\n",
    "        \n",
    "    # TODO: Get the predictions on the test set,\n",
    "    #       then get predictions on the first 300 training samples\n",
    "    start = time() # Get start time\n",
    "    predictions_test = learner.predict(X_test)\n",
    "    predictions_train = learner.predict(X_train)\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # TODO: Calculate the total prediction time\n",
    "    results['pred_time'] = end-start\n",
    "            \n",
    "    # TODO: Compute accuracy on the first 300 training samples\n",
    "    results['acc_train'] = accuracy_score(y_train, predictions_train)\n",
    "        \n",
    "    # TODO: Compute accuracy on test set\n",
    "    results['acc_test'] = accuracy_score(y_test, predictions_test)\n",
    "    \n",
    "    # TODO: Compute F-score on the the first 300 training samples\n",
    "    results['f_train'] = fbeta_score(y_train, predictions_train, beta=beta)\n",
    "        \n",
    "   # TODO: Compute F-score on the test set\n",
    "    results['f_test'] = fbeta_score(y_test, predictions_test, beta=beta)\n",
    "       \n",
    "    # Success\n",
    "    print (\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
    "        \n",
    "    # Return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Transaction_Type',\n",
       " 'Counts_investor',\n",
       " 'Counts_advisor',\n",
       " 'Rating',\n",
       " '1 Yr % Rank',\n",
       " '3 Yr % Rank',\n",
       " '1 Yr Return',\n",
       " '3 Yr Return',\n",
       " '1 Yr Excess Return vs Primary Ix',\n",
       " '3 Yr Excess Return vs Primary Ix',\n",
       " '1 Yr Excess Return vs Category Ix',\n",
       " '3 Yr Excess Return vs Category Ix',\n",
       " 'Net Flows',\n",
       " 'Morningstar_Category_Rating',\n",
       " 'AUM_investor_log',\n",
       " 'Shares_investor_log',\n",
       " 'AUM_advisor_log',\n",
       " 'Shares_advisor_log']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#column_list= ['AUM_investor_log','Counts_investor','Shares_investor_log','AUM_advisor_log','Shares_advisor_log','Rating','1 Yr % Rank','3 Yr % Rank','1 Yr Return','3 Yr Return','Net Flows','Morningstar_Category_Rating','Transaction_Type']\n",
    "see_activity= False\n",
    "\n",
    "column_list= [\n",
    "    'Transaction_Type',\n",
    "#    'Shares_investor',\n",
    "#    'AUM_investor',\n",
    "     'Counts_investor',\n",
    "     'Counts_advisor',\n",
    "#\t'Shares_advisor',\n",
    "#\t'AUM_advisor',\n",
    "#\t'Morningstar Category',\n",
    "#\t'Investment',\n",
    "\t'Rating',\n",
    "\t'1 Yr % Rank',\n",
    "\t'3 Yr % Rank',\n",
    "#\t'5 Yr % Rank',\n",
    "#\t'10 Yr % Rank',\n",
    "\t'1 Yr Return',\n",
    "\t'3 Yr Return',\n",
    "#\t'5 Yr Return',\n",
    "#\t'10 Yr Return',\n",
    "\t'1 Yr Excess Return vs Primary Ix',\n",
    "\t'3 Yr Excess Return vs Primary Ix',\n",
    "#\t'5 Yr Excess Return vs Primary Ix',\n",
    "#\t'10 Yr Excess Return vs Primary Ix',\n",
    "\t'1 Yr Excess Return vs Category Ix',\n",
    "\t'3 Yr Excess Return vs Category Ix',\n",
    "#\t'5 Yr Excess Return vs Category Ix',\n",
    "#\t'10 Yr Excess Return vs Category Ix',\n",
    "\t'Net Flows',\n",
    "\t'Morningstar_Category_Rating',\n",
    "#\t'investment_vehicle_segment',\n",
    "\t'AUM_investor_log',\n",
    "\t'Shares_investor_log',\n",
    "\t'AUM_advisor_log',\n",
    "\t'Shares_advisor_log',\n",
    "\t]\n",
    "\n",
    "if(see_activity):\n",
    "    column_list.extend(list(activity_df.columns[pd.Series(activity_df.columns).str.startswith('Activity')]))\n",
    "\n",
    "\n",
    "display(column_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### processing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping data by unique advisor id and month. Final output will store sums of the assets under managements and shares for each advisor in particular month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/ipykernel/__main__.py:101: RuntimeWarning: divide by zero encountered in log\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/ipykernel/__main__.py:103: RuntimeWarning: divide by zero encountered in log\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/ipykernel/__main__.py:104: RuntimeWarning: divide by zero encountered in log\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/ipykernel/__main__.py:108: RuntimeWarning: divide by zero encountered in log\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/ipykernel/__main__.py:111: RuntimeWarning: divide by zero encountered in log\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/ipykernel/__main__.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/ipykernel/__main__.py:161: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training na set has 19409 samples.\n",
      "Testing na set has 4853 samples.\n",
      "Training noNa set has 99782 samples.\n",
      "Testing noNa set has 24946 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/scipy/optimize/linesearch.py:414: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/ubuntu/.local/lib/python3.5/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression trained on 19409 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.5/site-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression': {0: {'acc_test': 0.66412528332989906,\n",
       "   'acc_train': 0.66608274511824417,\n",
       "   'f_test': 0.55827039834147785,\n",
       "   'f_train': 0.56646985149400608,\n",
       "   'pred_time': 0.0016150474548339844,\n",
       "   'train_time': 2.131662368774414}}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression trained on 99782 samples.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression': {0: {'acc_test': 0.66663994227531465,\n",
       "   'acc_train': 0.6646088472870858,\n",
       "   'f_test': 0.71371801850843752,\n",
       "   'f_train': 0.71323617282475271,\n",
       "   'pred_time': 0.0062944889068603516,\n",
       "   'train_time': 18.20057725906372}}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Propensity_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.835213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.026404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.067945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.156935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.067945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Propensity_Score\n",
       "0          0.835213\n",
       "1          0.026404\n",
       "2          0.067945\n",
       "3          0.156935\n",
       "4          0.067945"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "NO     1279\n",
       "YES     222\n",
       "Name: Redeem_Status, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Propensity_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.943226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.613030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.266147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.646299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.565217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Propensity_Score\n",
       "0          0.943226\n",
       "1          0.613030\n",
       "2          0.266147\n",
       "3          0.646299\n",
       "4          0.565217"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "YES    6911\n",
       "NO      302\n",
       "Name: Redeem_Status, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Propensity_Score</th>\n",
       "      <th>Redeem_Status</th>\n",
       "      <th>Unique_Advisor_Id</th>\n",
       "      <th>Unique_Investment_Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000332.0</td>\n",
       "      <td>14146.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000332.0</td>\n",
       "      <td>18654.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000332.0</td>\n",
       "      <td>3460.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000533.0</td>\n",
       "      <td>5538.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1003125.0</td>\n",
       "      <td>3460.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1009195.0</td>\n",
       "      <td>15354.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1009195.0</td>\n",
       "      <td>3533.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1009570.0</td>\n",
       "      <td>18381.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1009570.0</td>\n",
       "      <td>5841.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1014856.0</td>\n",
       "      <td>9320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1015449.0</td>\n",
       "      <td>9329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1015468.0</td>\n",
       "      <td>14146.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1015468.0</td>\n",
       "      <td>18654.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1015468.0</td>\n",
       "      <td>3460.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1015468.0</td>\n",
       "      <td>5875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1015468.0</td>\n",
       "      <td>9340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1016488.0</td>\n",
       "      <td>11537.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1016488.0</td>\n",
       "      <td>3460.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1016488.0</td>\n",
       "      <td>3588.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1017614.0</td>\n",
       "      <td>11659.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1018470.0</td>\n",
       "      <td>20092.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1018477.0</td>\n",
       "      <td>3482.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1018489.0</td>\n",
       "      <td>11659.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1018491.0</td>\n",
       "      <td>15241.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1018491.0</td>\n",
       "      <td>3840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1018491.0</td>\n",
       "      <td>3842.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1018493.0</td>\n",
       "      <td>4063.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1018506.0</td>\n",
       "      <td>3532.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1018506.0</td>\n",
       "      <td>3539.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1018509.0</td>\n",
       "      <td>12488.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4473</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4474</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4475</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4476</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4477</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4478</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4479</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4480</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4481</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4482</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4483</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4484</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4485</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4486</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4487</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4488</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4489</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4490</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4491</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4492</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4493</th>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4494</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4495</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4496</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4497</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4498</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4499</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4500</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4501</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4502</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4503 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Propensity_Score Redeem_Status  Unique_Advisor_Id  Unique_Investment_Id\n",
       "0                  NaN           NaN          1000332.0               14146.0\n",
       "1                  NaN           NaN          1000332.0               18654.0\n",
       "2                  NaN           NaN          1000332.0                3460.0\n",
       "3                  NaN           NaN          1000533.0                5538.0\n",
       "4                  NaN           NaN          1003125.0                3460.0\n",
       "5                  NaN           NaN          1009195.0               15354.0\n",
       "6                  NaN           NaN          1009195.0                3533.0\n",
       "7                  NaN           NaN          1009570.0               18381.0\n",
       "8                  NaN           NaN          1009570.0                5841.0\n",
       "9                  NaN           NaN          1014856.0                9320.0\n",
       "10                 NaN           NaN          1015449.0                9329.0\n",
       "11                 NaN           NaN          1015468.0               14146.0\n",
       "12                 NaN           NaN          1015468.0               18654.0\n",
       "13                 NaN           NaN          1015468.0                3460.0\n",
       "14                 NaN           NaN          1015468.0                5875.0\n",
       "15                 NaN           NaN          1015468.0                9340.0\n",
       "16                 NaN           NaN          1016488.0               11537.0\n",
       "17                 NaN           NaN          1016488.0                3460.0\n",
       "18                 NaN           NaN          1016488.0                3588.0\n",
       "19                 NaN           NaN          1017614.0               11659.0\n",
       "20                 NaN           NaN          1018470.0               20092.0\n",
       "21                 NaN           NaN          1018477.0                3482.0\n",
       "22                 NaN           NaN          1018489.0               11659.0\n",
       "23                 NaN           NaN          1018491.0               15241.0\n",
       "24                 NaN           NaN          1018491.0                3840.0\n",
       "25                 NaN           NaN          1018491.0                3842.0\n",
       "26                 NaN           NaN          1018493.0                4063.0\n",
       "27                 NaN           NaN          1018506.0                3532.0\n",
       "28                 NaN           NaN          1018506.0                3539.0\n",
       "29                 NaN           NaN          1018509.0               12488.0\n",
       "...                ...           ...                ...                   ...\n",
       "4473               NaN            NO                NaN                   NaN\n",
       "4474               NaN            NO                NaN                   NaN\n",
       "4475               NaN            NO                NaN                   NaN\n",
       "4476               NaN            NO                NaN                   NaN\n",
       "4477               NaN            NO                NaN                   NaN\n",
       "4478               NaN            NO                NaN                   NaN\n",
       "4479               NaN            NO                NaN                   NaN\n",
       "4480               NaN            NO                NaN                   NaN\n",
       "4481               NaN            NO                NaN                   NaN\n",
       "4482               NaN            NO                NaN                   NaN\n",
       "4483               NaN            NO                NaN                   NaN\n",
       "4484               NaN            NO                NaN                   NaN\n",
       "4485               NaN            NO                NaN                   NaN\n",
       "4486               NaN            NO                NaN                   NaN\n",
       "4487               NaN            NO                NaN                   NaN\n",
       "4488               NaN            NO                NaN                   NaN\n",
       "4489               NaN            NO                NaN                   NaN\n",
       "4490               NaN            NO                NaN                   NaN\n",
       "4491               NaN            NO                NaN                   NaN\n",
       "4492               NaN            NO                NaN                   NaN\n",
       "4493               NaN           YES                NaN                   NaN\n",
       "4494               NaN            NO                NaN                   NaN\n",
       "4495               NaN            NO                NaN                   NaN\n",
       "4496               NaN            NO                NaN                   NaN\n",
       "4497               NaN            NO                NaN                   NaN\n",
       "4498               NaN            NO                NaN                   NaN\n",
       "4499               NaN            NO                NaN                   NaN\n",
       "4500               NaN            NO                NaN                   NaN\n",
       "4501               NaN            NO                NaN                   NaN\n",
       "4502               NaN            NO                NaN                   NaN\n",
       "\n",
       "[4503 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Propensity_Score</th>\n",
       "      <th>Redeem_Status</th>\n",
       "      <th>Unique_Advisor_Id</th>\n",
       "      <th>Unique_Investment_Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000103.0</td>\n",
       "      <td>14147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000103.0</td>\n",
       "      <td>3534.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000103.0</td>\n",
       "      <td>3651.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000103.0</td>\n",
       "      <td>7668.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000103.0</td>\n",
       "      <td>9339.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000373.0</td>\n",
       "      <td>4008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000541.0</td>\n",
       "      <td>4008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001726.0</td>\n",
       "      <td>11540.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001726.0</td>\n",
       "      <td>3532.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001726.0</td>\n",
       "      <td>3538.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001726.0</td>\n",
       "      <td>4008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1002143.0</td>\n",
       "      <td>4811.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1002143.0</td>\n",
       "      <td>9329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1002831.0</td>\n",
       "      <td>19232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1002831.0</td>\n",
       "      <td>3459.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1002920.0</td>\n",
       "      <td>19245.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1002920.0</td>\n",
       "      <td>3476.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1003233.0</td>\n",
       "      <td>3532.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1003233.0</td>\n",
       "      <td>4008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1003233.0</td>\n",
       "      <td>8844.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1003335.0</td>\n",
       "      <td>14147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1003335.0</td>\n",
       "      <td>3460.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1003335.0</td>\n",
       "      <td>3532.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1003692.0</td>\n",
       "      <td>19229.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1003692.0</td>\n",
       "      <td>19230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1003692.0</td>\n",
       "      <td>20037.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1003692.0</td>\n",
       "      <td>3532.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1003692.0</td>\n",
       "      <td>3566.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1003692.0</td>\n",
       "      <td>9327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1004283.0</td>\n",
       "      <td>3476.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21609</th>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21610</th>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21611</th>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21612</th>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21613</th>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21614</th>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21615</th>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21616</th>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21617</th>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21618</th>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21619</th>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21620</th>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21621</th>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21622</th>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21623</th>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21624</th>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21625</th>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21626</th>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21627</th>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21628</th>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21629</th>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21630</th>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21631</th>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21632</th>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21633</th>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21634</th>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21635</th>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21636</th>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21637</th>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21638</th>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21639 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Propensity_Score Redeem_Status  Unique_Advisor_Id  Unique_Investment_Id\n",
       "0                   NaN           NaN          1000103.0               14147.0\n",
       "1                   NaN           NaN          1000103.0                3534.0\n",
       "2                   NaN           NaN          1000103.0                3651.0\n",
       "3                   NaN           NaN          1000103.0                7668.0\n",
       "4                   NaN           NaN          1000103.0                9339.0\n",
       "5                   NaN           NaN          1000373.0                4008.0\n",
       "6                   NaN           NaN          1000541.0                4008.0\n",
       "7                   NaN           NaN          1001726.0               11540.0\n",
       "8                   NaN           NaN          1001726.0                3532.0\n",
       "9                   NaN           NaN          1001726.0                3538.0\n",
       "10                  NaN           NaN          1001726.0                4008.0\n",
       "11                  NaN           NaN          1002143.0                4811.0\n",
       "12                  NaN           NaN          1002143.0                9329.0\n",
       "13                  NaN           NaN          1002831.0               19232.0\n",
       "14                  NaN           NaN          1002831.0                3459.0\n",
       "15                  NaN           NaN          1002920.0               19245.0\n",
       "16                  NaN           NaN          1002920.0                3476.0\n",
       "17                  NaN           NaN          1003233.0                3532.0\n",
       "18                  NaN           NaN          1003233.0                4008.0\n",
       "19                  NaN           NaN          1003233.0                8844.0\n",
       "20                  NaN           NaN          1003335.0               14147.0\n",
       "21                  NaN           NaN          1003335.0                3460.0\n",
       "22                  NaN           NaN          1003335.0                3532.0\n",
       "23                  NaN           NaN          1003692.0               19229.0\n",
       "24                  NaN           NaN          1003692.0               19230.0\n",
       "25                  NaN           NaN          1003692.0               20037.0\n",
       "26                  NaN           NaN          1003692.0                3532.0\n",
       "27                  NaN           NaN          1003692.0                3566.0\n",
       "28                  NaN           NaN          1003692.0                9327.0\n",
       "29                  NaN           NaN          1004283.0                3476.0\n",
       "...                 ...           ...                ...                   ...\n",
       "21609               NaN           YES                NaN                   NaN\n",
       "21610               NaN           YES                NaN                   NaN\n",
       "21611               NaN           YES                NaN                   NaN\n",
       "21612               NaN           YES                NaN                   NaN\n",
       "21613               NaN           YES                NaN                   NaN\n",
       "21614               NaN           YES                NaN                   NaN\n",
       "21615               NaN           YES                NaN                   NaN\n",
       "21616               NaN           YES                NaN                   NaN\n",
       "21617               NaN           YES                NaN                   NaN\n",
       "21618               NaN           YES                NaN                   NaN\n",
       "21619               NaN           YES                NaN                   NaN\n",
       "21620               NaN           YES                NaN                   NaN\n",
       "21621               NaN           YES                NaN                   NaN\n",
       "21622               NaN           YES                NaN                   NaN\n",
       "21623               NaN           YES                NaN                   NaN\n",
       "21624               NaN           YES                NaN                   NaN\n",
       "21625               NaN           YES                NaN                   NaN\n",
       "21626               NaN           YES                NaN                   NaN\n",
       "21627               NaN           YES                NaN                   NaN\n",
       "21628               NaN           YES                NaN                   NaN\n",
       "21629               NaN           YES                NaN                   NaN\n",
       "21630               NaN           YES                NaN                   NaN\n",
       "21631               NaN           YES                NaN                   NaN\n",
       "21632               NaN           YES                NaN                   NaN\n",
       "21633               NaN           YES                NaN                   NaN\n",
       "21634               NaN           YES                NaN                   NaN\n",
       "21635               NaN           YES                NaN                   NaN\n",
       "21636               NaN           YES                NaN                   NaN\n",
       "21637               NaN           YES                NaN                   NaN\n",
       "21638               NaN           YES                NaN                   NaN\n",
       "\n",
       "[21639 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transaction_df = pd.read_csv(os.path.join(path_to_data, transaction_file))\n",
    "investment_exp_df = pd.read_csv(os.path.join(path_to_data, investment_exp_file))\n",
    "#grouped_transaction_amounts_df = pd.read_csv(os.path.join(path_to_data, grouped_transaction_amounts))\n",
    "investment_segment_df = pd.read_csv(os.path.join(path_to_data, investment_segment))\n",
    "aum_df = pd.read_csv(os.path.join(path_to_data, aum_file))\n",
    "activity_df = pd.read_csv(os.path.join(path_to_data, activity_file))\n",
    "test_df = pd.read_csv(os.path.join(path_to_data,test_file))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "grouped_advisor_aum_df = aum_df.groupby(['Unique_Advisor_Id','Month']).agg({'AUM': 'mean','Shares':'mean','Unique_Investment_Id':'count'}).reset_index().rename(columns={'Unique_Investment_Id':'Counts'})\n",
    "grouped_investment_aum_df = aum_df.groupby(['Unique_Investment_Id','Month']).agg({'AUM': 'mean','Shares':'mean','Unique_Advisor_Id':'count'}).reset_index().rename(columns={'Unique_Advisor_Id':'Counts'})\n",
    "\n",
    "grouped_investment_aum_df['Year'],grouped_investment_aum_df['Month']=grouped_investment_aum_df['Month'].str.split(' /', 1).str\n",
    "grouped_advisor_aum_df['Year'],grouped_advisor_aum_df['Month']=grouped_advisor_aum_df['Month'].str.split(' /', 1).str\n",
    "\n",
    "transaction_df['Year'],transaction_df['Month']=transaction_df['Month'].str.split(' /', 1).str\n",
    "investment_exp_df['Year'],investment_exp_df['Month']=investment_exp_df['Month'].str.split(' /', 1).str\n",
    "aum_df['Year'],aum_df['Month']=aum_df['Month'].str.split(' /', 1).str\n",
    "activity_df['Year'],activity_df['Month']=activity_df['Month'].str.split(' /', 1).str\n",
    "#grouped_transaction_amounts_df['Year'],grouped_transaction_amounts_df['Month'] =grouped_transaction_amounts_df['Month'].str.split(' /', 1).str\n",
    "\n",
    "grouped_investment_aum_df['Mapping_Month']= grouped_investment_aum_df['Month'].astype(int).apply(lambda x : x+1)\n",
    "grouped_advisor_aum_df['Mapping_Month']= grouped_advisor_aum_df['Month'].astype(int).apply(lambda x : x+1)\n",
    "investment_exp_df['Mapping_Month']= investment_exp_df['Month'].astype(int).apply(lambda x : x+1)\n",
    "aum_df['Mapping_Month']= aum_df['Month'].astype(int).apply(lambda x : x+1)\n",
    "activity_df['Mapping_Month']= activity_df['Month'].astype(int).apply(lambda x : x+1)\n",
    "#grouped_transaction_amounts_df['Mapping_Month']= grouped_transaction_amounts_df['Month'].astype(int).apply(lambda x : x+1)\n",
    "\n",
    "\n",
    "transaction_df['Month'] =  transaction_df['Month'].astype(int).apply(lambda x : x+0)\n",
    "\n",
    "final_transaction = pd.merge(transaction_df, grouped_investment_aum_df, left_on=[\"Month\",\"Unique_Investment_Id\"],right_on=[\"Mapping_Month\",\"Unique_Investment_Id\"], how=\"left\") \n",
    "final_transaction = final_transaction.rename(columns={'Month_x': 'Month', 'AUM': 'AUM_investor','Year_x' : 'Year', 'Counts' : 'Counts_investor', 'Shares': 'Shares_investor','Month_y':'Month_actual'})\n",
    "final_transaction = final_transaction.drop('Year_y', 1)\n",
    "\n",
    "test_transaction = pd.merge(test_df, grouped_investment_aum_df[grouped_investment_aum_df[\"Mapping_Month\"]== 13], on=\"Unique_Investment_Id\", how=\"left\")\n",
    "test_transaction = test_transaction.rename(columns={ 'AUM': 'AUM_investor','Counts' : 'Counts_investor', 'Shares': 'Shares_investor'})\n",
    "\n",
    "final_transaction = pd.merge(final_transaction, grouped_advisor_aum_df, left_on=[\"Month\",\"Unique_Advisor_Id\"],right_on=[\"Mapping_Month\",\"Unique_Advisor_Id\"], how=\"left\") \n",
    "final_transaction = final_transaction.rename(columns={'Month_x': 'Month', 'AUM': 'AUM_advisor','Year_x' : 'Year', 'Counts' : 'Counts_advisor', 'Shares': 'Shares_advisor','Mapping_Month_x': 'Mapping_Month'})\n",
    "final_transaction = final_transaction.drop(['Year_y','Mapping_Month_y','Month_y'], 1)\n",
    "\n",
    "test_transaction = pd.merge(test_transaction, grouped_advisor_aum_df[grouped_advisor_aum_df[\"Mapping_Month\"]== 13], on=\"Unique_Advisor_Id\", how=\"left\")\n",
    "test_transaction = test_transaction.rename(columns={ 'AUM': 'AUM_advisor','Counts' : 'Counts_advisor', 'Shares': 'Shares_advisor','Month_x':'Month','Mapping_Month_x':'Mapping_Month'})\n",
    "test_transaction = test_transaction.drop(['Year_x','Year_y','Mapping_Month_y','Month_y','Mapping_Month'], 1)\n",
    "\n",
    "investment_exp_df['investment_vehicle_segment']= investment_segment_df['investment_vehicle_segment']\n",
    "investment_exp_df= investment_exp_df[investment_exp_df['Year']=='2016']\n",
    "activity_df = activity_df[activity_df['Year']=='2016']\n",
    "\n",
    "final_transaction_with_exp = pd.merge(final_transaction, investment_exp_df, left_on=[\"Month\",\"Unique_Investment_Id\"],right_on=[\"Mapping_Month\",\"Unique_Investment_Id\"], how=\"left\") \n",
    "final_transaction_with_exp = final_transaction_with_exp.rename(columns={'Month_x': 'Month', 'AUM': 'AUM_advisor','Year_x' : 'Year', 'Mapping_Month_x':'Mapping_Month'})\n",
    "final_transaction_with_exp = final_transaction_with_exp.drop(['Year_y','Mapping_Month_y','Month_y'], 1)\n",
    "#final_transaction_with_exp = pd.merge(final_transaction_with_exp, grouped_transaction_amounts_df, left_on=[\"Month\",\"Unique_Investment_Id\"],right_on=[\"Mapping_Month\",\"Unique_Investment_Id\"], how=\"left\") \n",
    "#final_transaction_with_exp = final_transaction_with_exp.drop(['Year_y','Mapping_Month_y','Month_y'], 1)\n",
    "\n",
    "test_transaction_with_exp = pd.merge(test_transaction, investment_exp_df[investment_exp_df[\"Mapping_Month\"]== 13 ], on=\"Unique_Investment_Id\", how=\"left\")\n",
    "#test_transaction_with_exp = pd.merge(test_transaction_with_exp, grouped_transaction_amounts_df[grouped_transaction_amounts_df[\"Mapping_Month\"]== 13 ], on=[\"Unique_Investment_Id\"], how=\"left\")\n",
    "\n",
    "#display(final_transaction_with_exp.head())\n",
    "#display(test_transaction_with_exp.head())\n",
    "\n",
    "##merging with activity\n",
    "if(see_activity):\n",
    "    final_transaction_with_exp = pd.merge(final_transaction_with_exp, activity_df, left_on=[\"Month\",\"Unique_Advisor_Id\"],right_on=[\"Mapping_Month\",\"Unique_Advisor_Id\"], how=\"left\") \n",
    "    test_transaction_with_exp = pd.merge(test_transaction_with_exp, activity_df[activity_df[\"Mapping_Month\"]== 13 ], on=\"Unique_Advisor_Id\", how=\"left\")\n",
    "\n",
    "'''\n",
    "final_transaction_with_exp['AUM_investor_log'] = np.log(final_transaction_with_exp['AUM_investor'])\n",
    "final_transaction_with_exp['Shares_investor_log'] = np.log(final_transaction_with_exp['Shares_investor'])\n",
    "\n",
    "final_transaction_with_exp['AUM_advisor_log'] = np.log(final_transaction_with_exp['AUM_advisor'])\n",
    "final_transaction_with_exp['Shares_advisor_log'] = np.log(final_transaction_with_exp['Shares_advisor'])\n",
    "\n",
    "\n",
    "test_transaction_with_exp['AUM_investor_log'] = np.log(test_transaction_with_exp['AUM_investor'])\n",
    "test_transaction_with_exp['Shares_investor_log'] = np.log(test_transaction_with_exp['Shares_investor'])\n",
    "\n",
    "test_transaction_with_exp['AUM_advisor_log'] = np.log(test_transaction_with_exp['AUM_advisor'])\n",
    "test_transaction_with_exp['Shares_advisor_log'] = np.log(test_transaction_with_exp['Shares_advisor'])\n",
    "\n",
    "\n",
    "#############################################\n",
    "final_transaction_with_exp['AUM_investor_log'] = (np.log(final_transaction_with_exp['AUM_investor']/final_transaction_with_exp['Counts_investor'])).where(final_transaction_with_exp['AUM_investor']!=0)\n",
    "final_transaction_with_exp['Shares_investor_log'] = (np.log(final_transaction_with_exp['Shares_investor']/final_transaction_with_exp['Counts_investor'])).where(final_transaction_with_exp['Shares_investor']!=0)\n",
    "\n",
    "final_transaction_with_exp['AUM_advisor_log'] = (np.log(final_transaction_with_exp['AUM_advisor']/final_transaction_with_exp['Counts_advisor'])).where(final_transaction_with_exp['AUM_advisor']!=0)\n",
    "final_transaction_with_exp['Shares_advisor_log'] = (np.log(final_transaction_with_exp['Shares_advisor']/final_transaction_with_exp['Counts_advisor'])).where(final_transaction_with_exp['Shares_advisor']!=0)\n",
    "\n",
    "\n",
    "test_transaction_with_exp['AUM_investor_log'] = (np.log(test_transaction_with_exp['AUM_investor']/test_transaction_with_exp['Counts_investor'])).where(test_transaction_with_exp['AUM_investor']!=0)\n",
    "test_transaction_with_exp['Shares_investor_log'] = (np.log(test_transaction_with_exp['Shares_investor']/test_transaction_with_exp['Counts_investor'])).where(test_transaction_with_exp['Shares_investor']!=0)\n",
    "\n",
    "test_transaction_with_exp['AUM_advisor_log'] = (np.log(test_transaction_with_exp['AUM_advisor']/test_transaction_with_exp['Counts_advisor'])).where(test_transaction_with_exp['AUM_advisor']!=0)\n",
    "test_transaction_with_exp['Shares_advisor_log'] = (np.log(test_transaction_with_exp['Shares_advisor']/test_transaction_with_exp['Counts_advisor'])).where(test_transaction_with_exp['Shares_advisor']!=0)\n",
    "##########################################################\n",
    "'''\n",
    "final_transaction_with_exp['AUM_investor_log'] = (np.log(final_transaction_with_exp['AUM_investor'])).where(final_transaction_with_exp['AUM_investor']!=0)\n",
    "final_transaction_with_exp['Shares_investor_log'] = (np.log(final_transaction_with_exp['Shares_investor'])).where(final_transaction_with_exp['Shares_investor']!=0)\n",
    "\n",
    "final_transaction_with_exp['AUM_advisor_log'] = (np.log(final_transaction_with_exp['AUM_advisor'])).where(final_transaction_with_exp['AUM_advisor']!=0)\n",
    "final_transaction_with_exp['Shares_advisor_log'] = (np.log(final_transaction_with_exp['Shares_advisor'])).where(final_transaction_with_exp['Shares_advisor']!=0)\n",
    "\n",
    "\n",
    "test_transaction_with_exp['AUM_investor_log'] = (np.log(test_transaction_with_exp['AUM_investor'])).where(test_transaction_with_exp['AUM_investor']!=0)\n",
    "test_transaction_with_exp['Shares_investor_log'] = (np.log(test_transaction_with_exp['Shares_investor'])).where(test_transaction_with_exp['Shares_investor']!=0)\n",
    "\n",
    "test_transaction_with_exp['AUM_advisor_log'] = (np.log(test_transaction_with_exp['AUM_advisor'])).where(test_transaction_with_exp['AUM_advisor']!=0)\n",
    "test_transaction_with_exp['Shares_advisor_log'] = (np.log(test_transaction_with_exp['Shares_advisor'])).where(test_transaction_with_exp['Shares_advisor']!=0)\n",
    "\n",
    "final_transaction_with_exp= final_transaction_with_exp[final_transaction_with_exp.Month !=1]\n",
    "\n",
    "#final_transaction_with_exp= final_transaction_with_exp.dropna()\n",
    "\n",
    "\n",
    "required_train_df = final_transaction_with_exp.filter(column_list)\n",
    "required_train_df['Transaction_Type']= required_train_df.apply(lambda x: 0 if x['Transaction_Type']== 'P' else 1, axis=1)\n",
    "\n",
    "if(see_activity):\n",
    "    required_train_df[required_train_df.columns[pd.Series(required_train_df.columns).str.startswith('Activity')]] = required_train_df[required_train_df.columns[pd.Series(required_train_df.columns).str.startswith('Activity')]].fillna(0)\n",
    "\n",
    "required_test_df = test_transaction_with_exp.filter(column_list)\n",
    "\n",
    "if(see_activity):\n",
    "    required_test_df[required_test_df.columns[pd.Series(required_test_df.columns).str.startswith('Activity')]] = required_test_df[required_test_df.columns[pd.Series(required_test_df.columns).str.startswith('Activity')]].fillna(0)\n",
    "    \n",
    "required_train_df_meanNa= required_train_df.fillna(required_train_df.median())\n",
    "required_test_df_meanNa = required_test_df.fillna(required_test_df.median())\n",
    "required_train_df_na = required_train_df_meanNa[required_train_df.isnull().any(axis=1)]\n",
    "required_test_df_na = required_test_df_meanNa[required_test_df.isnull().any(axis=1)]\n",
    "\n",
    "required_train_df_noNa= required_train_df_meanNa[required_train_df.isnull().any(axis=1)== False]\n",
    "required_test_df_noNa = required_test_df_meanNa[required_test_df.isnull().any(axis=1)== False]\n",
    "\n",
    "test_df_na = test_df[required_test_df.isnull().any(axis=1)]\n",
    "test_df_noNa = test_df[required_test_df.isnull().any(axis=1)== False]\n",
    "\n",
    "\n",
    "# Split the data into features and target label\n",
    "transaction_type_na = required_train_df_na['Transaction_Type']\n",
    "transaction_type_noNa = required_train_df_noNa['Transaction_Type']\n",
    "\n",
    "features_raw_na = required_train_df_na.drop('Transaction_Type', axis = 1)\n",
    "test_raw_na = required_test_df_na\n",
    "features_raw_noNa = required_train_df_noNa.drop('Transaction_Type', axis = 1)\n",
    "test_raw_noNa = required_test_df_noNa\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "var_mod = column_list\n",
    "#var_mod.remove('Transaction_Type')\n",
    "le = LabelEncoder()\n",
    "for i in var_mod:\n",
    "    if i == 'Transaction_Type' \\\n",
    "    or i == 'Net Flows' \\\n",
    "    or i == 'AUM_investor_log' \\\n",
    "    or i == 'Shares_investor_log' \\\n",
    "    or i == 'AUM_advisor_log' \\\n",
    "    or i == 'Shares_advisor_log':\n",
    "        continue\n",
    "    features_raw_na[i] = le.fit_transform(features_raw_na[i])\n",
    "    test_raw_na[i] = le.fit_transform(test_raw_na[i])\n",
    "    features_raw_noNa[i] = le.fit_transform(features_raw_noNa[i])\n",
    "    test_raw_noNa[i] = le.fit_transform(test_raw_noNa[i])\n",
    "    \n",
    "###########################################################3\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Split the 'features' and 'transaction_type' data into training and testing sets\n",
    "X_train_na, X_test_na, y_train_na, y_test_na = train_test_split(features_raw_na, transaction_type_na, test_size = 0.2, random_state = 0)\n",
    "X_train_noNa, X_test_noNa, y_train_noNa, y_test_noNa = train_test_split(features_raw_noNa, transaction_type_noNa, test_size = 0.2, random_state = 0)\n",
    "\n",
    "\n",
    "# Show the results of the split\n",
    "print (\"Training na set has {} samples.\".format(X_train_na.shape[0]))\n",
    "print (\"Testing na set has {} samples.\".format(X_test_na.shape[0]))\n",
    "\n",
    "print (\"Training noNa set has {} samples.\".format(X_train_noNa.shape[0]))\n",
    "print (\"Testing noNa set has {} samples.\".format(X_test_noNa.shape[0]))\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "\n",
    "# TODO: Import the three supervised learning models from sklearn\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier,RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# TODO: Initialize the three models\n",
    "clf_A_na = LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
    "          verbose=0, warm_start=False)\n",
    "clf_A_noNa = LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
    "          verbose=0, warm_start=False)\n",
    "clf_B = LinearSVC(random_state=101)\n",
    "clf_C = GaussianNB()\n",
    "clf_Ada = AdaBoostClassifier()\n",
    "clf_Grad = GradientBoostingClassifier()\n",
    "clf_KNN = KNeighborsClassifier()\n",
    "clf_Dec = DecisionTreeClassifier()\n",
    "clf_SGD = SGDClassifier()\n",
    "clf_Ran = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "\n",
    "# TODO: Calculate the number of samples for 1%, 10%, and 100% of the training data\n",
    "n_train = len(y_train_na)\n",
    "samples_1 = int(n_train * 0.01)\n",
    "samples_10 = int(n_train * 0.1)\n",
    "samples_100 = n_train\n",
    "\n",
    "# Collect results on the learners\n",
    "results_na = {}\n",
    "#for clf in [clf_A, clf_B, clf_C, clf_Ada, clf_Grad,clf_KNN ,clf_Dec, clf_SGD]:\n",
    "for clf in [clf_A_na]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    results_na[clf_name] = {}\n",
    "    for i, samples in enumerate([samples_100]):\n",
    "        results_na[clf_name][i] = \\\n",
    "        train_predict(clf, samples, X_train_na, y_train_na, X_test_na, y_test_na)\n",
    "        \n",
    "display(results_na)\n",
    "\n",
    "n_train = len(y_train_noNa)\n",
    "samples_1 = int(n_train * 0.01)\n",
    "samples_10 = int(n_train * 0.1)\n",
    "samples_100 = n_train\n",
    "# Collect results on the learners\n",
    "results_noNa = {}\n",
    "#for clf in [clf_A, clf_B, clf_C, clf_Ada, clf_Grad,clf_KNN ,clf_Dec, clf_SGD]:\n",
    "for clf in [clf_A_noNa]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    results_noNa[clf_name] = {}\n",
    "    for i, samples in enumerate([samples_100]):\n",
    "        results_noNa[clf_name][i] = \\\n",
    "        train_predict(clf, samples, X_train_noNa, y_train_noNa, X_test_noNa, y_test_noNa)\n",
    "        \n",
    "display(results_noNa)\n",
    "\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "for best_clf in [clf_A_na,clf_A_noNa]:\n",
    "    if best_clf == clf_A_na:\n",
    "        filename = 'logistic_regression_NA_invesco.joblib.pkl'\n",
    "        test_raw= test_raw_na\n",
    "    else:\n",
    "        filename = 'logistic_regression_noNA_invesco.joblib.pkl'\n",
    "        test_raw= test_raw_noNa\n",
    "\n",
    "    _ = joblib.dump(best_clf, filename, compress=9)\n",
    "\n",
    "    clf_loaded = joblib.load(filename)\n",
    "    print(\"file loaded\")\n",
    "\n",
    "    pred = clf_loaded.predict(test_raw)\n",
    "    pred_prob = clf_loaded.predict_proba(test_raw)\n",
    "\n",
    "    pred_prob = pd.DataFrame(pred_prob[:,1],columns=[\"Propensity_Score\"])\n",
    "    display(pred_prob[:5])\n",
    "\n",
    "    pred_df= pd.DataFrame(pred,columns=[\"Redeem_Status\"])\n",
    "\n",
    "    pred_df=pred_df.replace([0,1],['NO','YES'])\n",
    "    pred_df.head()\n",
    "\n",
    "    display(pred_df['Redeem_Status'].value_counts())\n",
    "    \n",
    "    if best_clf == clf_A_na:\n",
    "        result_na = pd.concat([test_df_na.reset_index(drop=True), pred_prob.reset_index(drop=True), pred_df.reset_index(drop=True)],ignore_index=True, axis=1)\n",
    "        \n",
    "    else:\n",
    "        result_noNa = pd.concat([test_df_noNa.reset_index(drop=True), pred_prob.reset_index(drop=True), pred_df.reset_index(drop=True)],ignore_index=True ,axis=1)\n",
    "    \n",
    "display(result_na)\n",
    "display(result_noNa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1501, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_na.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1501, 17)\n",
      "(8714, 17)\n",
      "(7213, 17)\n"
     ]
    }
   ],
   "source": [
    "print(required_test_df_na.shape)\n",
    "print(required_test_df_meanNa.shape)\n",
    "print(required_test_df_noNa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000332</td>\n",
       "      <td>14146</td>\n",
       "      <td>0.835213</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000332</td>\n",
       "      <td>18654</td>\n",
       "      <td>0.026404</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000332</td>\n",
       "      <td>3460</td>\n",
       "      <td>0.067945</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000533</td>\n",
       "      <td>5538</td>\n",
       "      <td>0.156935</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1003125</td>\n",
       "      <td>3460</td>\n",
       "      <td>0.067945</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1         2    3\n",
       "5   1000332  14146  0.835213  YES\n",
       "6   1000332  18654  0.026404   NO\n",
       "7   1000332   3460  0.067945   NO\n",
       "9   1000533   5538  0.156935   NO\n",
       "21  1003125   3460  0.067945   NO"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000103</td>\n",
       "      <td>14147</td>\n",
       "      <td>0.943226</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000103</td>\n",
       "      <td>3534</td>\n",
       "      <td>0.613030</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000103</td>\n",
       "      <td>3651</td>\n",
       "      <td>0.266147</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000103</td>\n",
       "      <td>7668</td>\n",
       "      <td>0.646299</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000103</td>\n",
       "      <td>9339</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1         2    3\n",
       "0  1000103  14147  0.943226  YES\n",
       "1  1000103   3534  0.613030  YES\n",
       "2  1000103   3651  0.266147   NO\n",
       "3  1000103   7668  0.646299  YES\n",
       "4  1000103   9339  0.565217  YES"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "na_index_list= test_df[required_test_df.isnull().any(axis=1)].index.tolist()\n",
    "noNa_index_list = test_df[required_test_df.isnull().any(axis=1)== False].index.tolist()\n",
    "result_na = result_na.set_index([na_index_list]) \n",
    "result_noNa = result_noNa.set_index([noNa_index_list])\n",
    "\n",
    "\n",
    "\n",
    "display(result_na.head())\n",
    "display(result_noNa.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000103</td>\n",
       "      <td>14147</td>\n",
       "      <td>0.943226</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000103</td>\n",
       "      <td>3534</td>\n",
       "      <td>0.613030</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000103</td>\n",
       "      <td>3651</td>\n",
       "      <td>0.266147</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000103</td>\n",
       "      <td>7668</td>\n",
       "      <td>0.646299</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000103</td>\n",
       "      <td>9339</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000332</td>\n",
       "      <td>14146</td>\n",
       "      <td>0.835213</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000332</td>\n",
       "      <td>18654</td>\n",
       "      <td>0.026404</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000332</td>\n",
       "      <td>3460</td>\n",
       "      <td>0.067945</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000373</td>\n",
       "      <td>4008</td>\n",
       "      <td>0.876855</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000533</td>\n",
       "      <td>5538</td>\n",
       "      <td>0.156935</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1         2    3\n",
       "0  1000103  14147  0.943226  YES\n",
       "1  1000103   3534  0.613030  YES\n",
       "2  1000103   3651  0.266147   NO\n",
       "3  1000103   7668  0.646299  YES\n",
       "4  1000103   9339  0.565217  YES\n",
       "5  1000332  14146  0.835213  YES\n",
       "6  1000332  18654  0.026404   NO\n",
       "7  1000332   3460  0.067945   NO\n",
       "8  1000373   4008  0.876855  YES\n",
       "9  1000533   5538  0.156935   NO"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test= pd.concat([result_na,result_noNa]).sort_index()\n",
    "final_test.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique_Advisor_Id</th>\n",
       "      <th>Unique_Investment_Id</th>\n",
       "      <th>Propensity_Score</th>\n",
       "      <th>Redeem_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000103</td>\n",
       "      <td>14147</td>\n",
       "      <td>0.967143</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000103</td>\n",
       "      <td>3534</td>\n",
       "      <td>0.726910</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000103</td>\n",
       "      <td>3651</td>\n",
       "      <td>0.242776</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000103</td>\n",
       "      <td>7668</td>\n",
       "      <td>0.799177</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000103</td>\n",
       "      <td>9339</td>\n",
       "      <td>0.500785</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unique_Advisor_Id  Unique_Investment_Id  Propensity_Score Redeem_Status\n",
       "0            1000103                 14147          0.967143           YES\n",
       "1            1000103                  3534          0.726910           YES\n",
       "2            1000103                  3651          0.242776            NO\n",
       "3            1000103                  7668          0.799177           YES\n",
       "4            1000103                  9339          0.500785           YES"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.concat([test_df, pred_prob, pred_df], axis=1)\n",
    "\n",
    "\n",
    "result.to_csv('test_data_v6-usingMeanForAUM.csv',index=False)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#result.to_csv('test_data_v5-removednetflows.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
